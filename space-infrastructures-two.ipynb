{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dascient/space-infrastructures-two?scriptVersionId=230410398\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"id":"9661dcdc-45d4-48be-9ed5-e8f309205f38","cell_type":"markdown","source":"# Revolutionary Data Science for Space-Based Infrastructure\n\nIn this notebook, you will explore innovative techniques including:\n\n- **Predictive Maintenance** with advanced time-series forecasting\n- **Anomaly Detection** using classical methods and deep learning (LSTM Autoencoders)\n- **Orbital Optimization** via differential evolution and a simulated reinforcement learning approach\n- **Graph Neural Networks (GNN)** for satellite constellation analysis (conceptual outline)\n- **Space Weather Prediction** with hyperparameter-tuned XGBoost\n- **Unsupervised Clustering** using UMAP and HDBSCAN\n- **Ensemble Learning** through stacking models","metadata":{}},{"id":"d0cd888b-4ae5-4496-9e08-7a9fc427fb51","cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom prophet import Prophet\nfrom sklearn.ensemble import IsolationForest\nimport plotly \nprint(plotly.__version__)\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report\nfrom scipy.optimize import differential_evolution\nfrom sklearn.model_selection import GridSearchCV\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport torch\nimport torch.nn as nn\nimport umap\nimport hdbscan\nimport ipywidgets as widgets\nfrom ipywidgets import interact\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\ntorch.manual_seed(42)\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T19:18:43.202675Z","iopub.execute_input":"2025-03-29T19:18:43.203191Z"}},"outputs":[{"name":"stdout","text":"5.24.1\n","output_type":"stream"}],"execution_count":null},{"id":"9f58d151-2ed2-41ee-9b0f-c8e103665f55","cell_type":"code","source":"# Simulate Enhanced Satellite Telemetry Data with Additional Features\nnum_samples = 200\nsatellite_data = pd.DataFrame({\n    'timestamp': pd.date_range(start='2025-01-01', periods=num_samples, freq='H'),\n    'component_health': np.random.rand(num_samples),\n    'component_temp': np.random.normal(20, 5, num_samples),\n    'battery_level': np.random.uniform(50, 100, num_samples),\n    'altitude': np.random.uniform(350, 450, num_samples),\n    'velocity': np.random.uniform(7.5, 8.0, num_samples),\n    'radiation_level': np.random.uniform(0, 5, num_samples)  \n})\n\nprint('Sample Enhanced Satellite Telemetry Data:')\nprint(satellite_data.head())\n\nprint('\\nData Summary:')\nprint(satellite_data.describe())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fe224bce-2359-4640-a444-6461dae00921","cell_type":"code","source":"# Advanced Data Visualization with Plotly (Time Series Trends)\nfig = px.line(satellite_data, x='timestamp', y=['component_temp', 'battery_level', 'radiation_level'], \n              title='Telemetry Trends Over Time', \n              labels={'value':'Measurement', 'variable':'Parameter'})\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fdd31780-c73b-458b-8069-b9bda3d5f057","cell_type":"code","source":"# Enhanced Predictive Maintenance using Prophet\ndf_prophet = satellite_data[['timestamp', 'component_health']].rename(columns={'timestamp':'ds', 'component_health':'y'})\nprophet_model = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=False)\nprophet_model.fit(df_prophet)\nfuture_dates = prophet_model.make_future_dataframe(periods=100, freq='H')\nforecast = prophet_model.predict(future_dates)\n\n# Plot forecast and its components\nfig1 = prophet_model.plot(forecast)\nplt.title('Enhanced Predictive Maintenance Forecast')\nplt.show()\n\nfig2 = prophet_model.plot_components(forecast)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3e1a0bb9-29e2-48ec-9761-fe18d97c3d82","cell_type":"code","source":"# Anomaly Detection with Isolation Forest\niso_model = IsolationForest(contamination=0.05, random_state=42)\nsatellite_data['anomaly'] = iso_model.fit_predict(satellite_data[['component_temp', 'battery_level', 'radiation_level']])\nanomalies = satellite_data[satellite_data['anomaly'] == -1]\n\nprint('Detected Anomalies (Isolation Forest):')\nprint(anomalies.head())\n\nplt.figure(figsize=(10, 6))\nplt.scatter(satellite_data['component_temp'], satellite_data['battery_level'], c='blue', label='Normal')\nplt.scatter(anomalies['component_temp'], anomalies['battery_level'], c='red', label='Anomaly')\nplt.xlabel('Component Temperature')\nplt.ylabel('Battery Level')\nplt.title('Isolation Forest Anomaly Detection')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4cf1df21-1131-43d4-a834-da0bb4041403","cell_type":"code","source":"# Deep Learning based Anomaly Detection using LSTM Autoencoder\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Preprocess data for LSTM\nfeatures = ['component_temp', 'battery_level', 'radiation_level']\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(satellite_data[features])\n\n# Create sequences of length 10\ndef create_sequences(data, seq_length=10):\n    xs = []\n    for i in range(len(data) - seq_length):\n        x = data[i:(i+seq_length)]\n        xs.append(x)\n    return np.array(xs)\n\nseq_length = 10\nX_lstm = create_sequences(scaled_data, seq_length)\n\n# Build the LSTM Autoencoder model\ninput_dim = X_lstm.shape[2]\ntimesteps = X_lstm.shape[1]\n\nlstm_model = keras.Sequential([\n    layers.LSTM(64, activation='relu', input_shape=(timesteps, input_dim), return_sequences=True),\n    layers.LSTM(32, activation='relu', return_sequences=False),\n    layers.RepeatVector(timesteps),\n    layers.LSTM(32, activation='relu', return_sequences=True),\n    layers.LSTM(64, activation='relu', return_sequences=True),\n    layers.TimeDistributed(layers.Dense(input_dim))\n])\n\nlstm_model.compile(optimizer='adam', loss='mse')\nlstm_model.summary()\n\n# Train the autoencoder\nhistory = lstm_model.fit(X_lstm, X_lstm, epochs=20, batch_size=16, validation_split=0.1, verbose=0)\n\nplt.figure(figsize=(8,4))\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('LSTM Autoencoder Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Calculate reconstruction error\nX_lstm_pred = lstm_model.predict(X_lstm)\nreconstruction_error = np.mean(np.abs(X_lstm_pred - X_lstm), axis=(1,2))\n\n# Determine anomaly threshold (mean + 2*std)\nthreshold = np.mean(reconstruction_error) + 2*np.std(reconstruction_error)\nprint('LSTM Reconstruction Error Threshold:', threshold)\n\n# Flag anomalies\nanomaly_flags = reconstruction_error > threshold\nprint('Detected anomalies (LSTM Autoencoder):', np.sum(anomaly_flags))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"645450a8-64aa-4f50-bcd8-0ac0899bb8c0","cell_type":"code","source":"# Orbital Optimization with Differential Evolution and a Simulated Reinforcement Learning Approach\n\ndef orbital_cost(params):\n    delta_v, transfer_time = params\n    # Advanced cost function with an added penalty for mismatch between delta_v and transfer_time\n    return delta_v**2 + transfer_time + 0.5 * abs(delta_v - transfer_time)\n\nbounds = [(0, 10), (0.5, 5)]\nresult = differential_evolution(orbital_cost, bounds, seed=42)\nprint('Optimized orbital parameters (Differential Evolution):', result.x)\n\n# (Simulated) Reinforcement Learning for Orbital Maneuver Optimization\nimport random\n\ndef simulate_orbital_rl(steps=50):\n    best_score = float('inf')\n    best_action = None\n    action = np.array([random.uniform(0, 10), random.uniform(0.5, 5)])\n    for _ in range(steps):\n        # Random perturbation to simulate exploration\n        action += np.random.normal(0, 0.1, size=2)\n        score = orbital_cost(action)\n        if score < best_score:\n            best_score = score\n            best_action = action.copy()\n    return best_action, best_score\n\nrl_action, rl_score = simulate_orbital_rl()\nprint('Optimized orbital parameters (Simulated RL):', rl_action)\nprint('RL Optimization Score:', rl_score)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a7ad2112-bd11-474a-907f-855a70bd47f8","cell_type":"markdown","source":"## Graph Neural Networks (GNN) for Satellite Constellation Analysis\n\nGraph Neural Networks are ideal for modeling the complex interactions within satellite constellations. The following outline provides a conceptual roadmap using PyTorch Geometric:\n\n1. **Data Preparation:** Construct a graph with nodes representing satellites and edges denoting communication or proximity.\n2. **Model Design:** Build a GNN (e.g., using GCN or GAT layers) to capture spatial and temporal dynamics.\n3. **Training:** Apply supervised or unsupervised methods depending on the task (e.g., clustering, anomaly detection).\n4. **Evaluation:** Use domain-specific metrics to assess performance.\n\nDue to the extensive setup required, this section serves as a conceptual guide for future implementation.","metadata":{}},{"id":"7ff37a4f-01f6-4077-9c02-8d2b8219a195","cell_type":"code","source":"# Space Weather Prediction using XGBoost with Hyperparameter Tuning\nX = satellite_data[['component_temp', 'battery_level', 'altitude', 'velocity', 'radiation_level']]\ny = np.random.randint(0, 2, size=len(satellite_data))  # Binary target indicating space weather event\n\ntrain_size = int(0.8 * len(satellite_data))\nX_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\ny_train, y_test = y[:train_size], y[train_size:]\n\nxgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\nparam_grid = {\n    'max_depth': [3, 5, 7],\n    'n_estimators': [50, 100, 150],\n    'learning_rate': [0.01, 0.1, 0.2]\n}\n\ngrid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='accuracy', verbose=1)\ngrid_search.fit(X_train, y_train)\n\nprint('Best Parameters:', grid_search.best_params_)\n\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_test)\n\nprint('\\nClassification Report for Space Weather Prediction:')\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c8562ee3-6fd5-4d8e-a982-5682d3e2aacc","cell_type":"code","source":"# Unsupervised Clustering using UMAP and HDBSCAN\n\numap_reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='euclidean', random_state=42)\numap_embedding = umap_reducer.fit_transform(satellite_data[['component_temp', 'battery_level', 'radiation_level']])\n\nhdb = hdbscan.HDBSCAN(min_cluster_size=5)\ncluster_labels = hdb.fit_predict(umap_embedding)\n\nsatellite_data['cluster'] = cluster_labels\n\nfig = px.scatter(umap_embedding, x=0, y=1, color=cluster_labels.astype(str), \n                 title='UMAP Projection and HDBSCAN Clustering')\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a968f994-886d-4ff0-ba3d-b47fc322daab","cell_type":"code","source":"# Ensemble Learning: Stacking Models for Enhanced Predictions\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\n# Define base models and meta-model\nbase_models = [\n    ('xgb', xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n    ('svc', SVC(probability=True))\n]\nmeta_model = LogisticRegression()\n\nstack_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=3)\n\nstack_model.fit(X_train, y_train)\nstack_pred = stack_model.predict(X_test)\n\nprint('\\nClassification Report for Stacking Ensemble:')\nprint(classification_report(y_test, stack_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"01457b19-9f21-42a5-935f-d81f11a31132","cell_type":"markdown","source":"## Conclusion & Future Work\n\nThis notebook has demonstrated a wide array of innovative, forward-thinking techniques for optimizing space-based infrastructure. It covers:\n\n- **Predictive Maintenance:** Advanced forecasting with Prophet\n- **Anomaly Detection:** Both Isolation Forest and deep learning LSTM autoencoders\n- **Orbital Optimization:** Differential evolution combined with simulated reinforcement learning\n- **Graph Neural Networks:** A conceptual roadmap for satellite constellation analysis\n- **Space Weather Prediction:** Hyperparameter-tuned XGBoost\n- **Unsupervised Clustering:** UMAP for dimensionality reduction and HDBSCAN for clustering\n- **Ensemble Learning:** Model stacking for enhanced predictions\n\n### Future Extensions\n\n1. **Real-Time Data Integration:** Connect live telemetry feeds for dynamic analysis.\n2. **Deployment & Monitoring:** Develop production-grade pipelines with containerized microservices and real-time dashboards.\n3. **Advanced Deep Learning:** Explore transformer-based architectures for forecasting and anomaly detection.\n4. **Multi-Agent Reinforcement Learning:** Implement cooperative frameworks for orbital maneuver planning.\n5. **Data Fusion:** Integrate external datasets (e.g., space weather, environmental data) to enrich model inputs.\n\nThis notebook serves as a comprehensive resource and a launchpad for next-generation AI-driven space infrastructure optimization.","metadata":{}},{"id":"91d89187-389e-4754-99c8-2f365b40abfe","cell_type":"code","source":"# Alluvial Diagram using Plotly Sankey Diagram for Satellite Data Flows\n\n# For demonstration, we aggregate flows from satellite clusters to anomaly states\ncluster_counts = satellite_data.groupby(['cluster', 'anomaly']).size().reset_index(name='count')\n\n# Define nodes: clusters (e.g., 'Cluster -1', 'Cluster 0', etc.) and anomaly states ('Normal', 'Anomaly')\nclusters = sorted(satellite_data['cluster'].unique())\nnodes = [\"Cluster \" + str(c) for c in clusters] + [\"Normal\", \"Anomaly\"]\n\n# Create mapping from node name to index\nnode_dict = {name: i for i, name in enumerate(nodes)}\n\nsources = []\ntargets = []\nvalues = []\n\nfor idx, row in cluster_counts.iterrows():\n    cluster_label = row['cluster']\n    anomaly_state = row['anomaly']\n    count = row['count']\n    source_node = \"Cluster \" + str(cluster_label)\n    target_node = \"Normal\" if anomaly_state == 1 else \"Anomaly\"\n    sources.append(node_dict[source_node])\n    targets.append(node_dict[target_node])\n    values.append(count)\n\nsankey_fig = go.Figure(data=[go.Sankey(\n    node = dict(\n      pad = 15,\n      thickness = 20,\n      line = dict(color = \"black\", width = 0.5),\n      label = nodes,\n      color = \"blue\"\n    ),\n    link = dict(\n      source = sources,\n      target = targets,\n      value = values\n    ))])\n\nsankey_fig.update_layout(title_text=\"Satellite Cluster to Anomaly State Flow\", font_size=10)\nsankey_fig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"af079441-f8db-49b4-bd18-82d5929c2169","cell_type":"code","source":"# Interactive Scatter Plot with ipywidgets for Cluster Filtering\ndef interactive_scatter(cluster_label):\n    filtered_data = satellite_data[satellite_data['cluster'] == cluster_label]\n    fig = px.scatter(filtered_data, x=\"component_temp\", y=\"battery_level\",\n                     color=\"radiation_level\", size=\"altitude\",\n                     title=f\"Satellite Data for Cluster {cluster_label}\")\n    fig.show()\n\nunique_clusters = sorted(satellite_data['cluster'].unique())\ninteract(interactive_scatter, cluster_label=widgets.Dropdown(options=unique_clusters, description='Cluster:'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5a5efbcc-7639-45ba-99d8-f96ef048c821","cell_type":"code","source":"# Interactive Dashboard Overview with Plotly Subplots\nfrom plotly.subplots import make_subplots\n\nfig_dashboard = make_subplots(rows=1, cols=2, subplot_titles=(\"Component Temp vs Battery Level\", \"Distribution of Radiation Levels\"))\n\nfig_dashboard.add_trace(\n    go.Scatter(x=satellite_data['component_temp'], y=satellite_data['battery_level'],\n               mode='markers', \n               marker=dict(color=satellite_data['radiation_level'], colorscale='Viridis', showscale=True),\n               name='Telemetry Data'),\n    row=1, col=1\n)\n\nfig_dashboard.add_trace(\n    go.Histogram(x=satellite_data['radiation_level'], nbinsx=20, name='Radiation Levels'),\n    row=1, col=2\n)\n\nfig_dashboard.update_layout(title_text=\"Interactive Dashboard Overview\", showlegend=False)\nfig_dashboard.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7ff9ae95-71c4-4d42-89b9-067258125e62","cell_type":"code","source":"# Comprehensive Overview Metrics Table using Plotly\noverview_metrics = {\n    \"Total Samples\": [len(satellite_data)],\n    \"Mean Component Health\": [satellite_data['component_health'].mean()],\n    \"Anomaly Count (Isolation Forest)\": [len(satellite_data[satellite_data['anomaly'] == -1])],\n    \"Unique Clusters (HDBSCAN)\": [len(satellite_data['cluster'].unique())]\n}\n\noverview_df = pd.DataFrame(overview_metrics)\n\ntable_fig = go.Figure(data=[go.Table(\n    header=dict(values=list(overview_df.columns),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[overview_df[col] for col in overview_df.columns],\n               fill_color='lavender',\n               align='left'))\n])\n\ntable_fig.update_layout(title=\"Comprehensive Overview Metrics\")\ntable_fig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}