{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Welcome to our Universe\n## [@donutz.ai](www.donutz.ai/#)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb\nimport lightgbm as lgb\n\n# Load the dataset\ndf = pd.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet')\ndf = pd.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet')\n\n# Display basic info\nprint(train.info())\nprint(test.info())\n\n# Check for missing values\nprint(train.isnull().sum())\n#/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:18:03.663495Z","iopub.execute_input":"2025-01-04T09:18:03.663833Z","execution_failed":"2025-01-04T09:18:35.572Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploration de Data\n\nNext, we'll explore the structure of the data and visualize the distribution of target values. We also check for missing values and handle them appropriately.","metadata":{}},{"cell_type":"code","source":"# Check for class imbalance\nsns.countplot(x='action', data=train)\nplt.title('Distribution of Target Variable \"Action\"')\nplt.show()\n\n# Drop rows where 'weight' is 0 (these are typically not useful for training)\ntrain = train[train['weight'] > 0]\n\n# Feature exploration - basic statistics of the features\nprint(train.describe())\n\n# Check missing values\nprint(train.isnull().sum())","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-04T09:18:35.573Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocess the Data\n\nWe'll handle missing values by imputing or dropping them. Additionally, weâ€™ll scale the features to make sure the model performs optimally.","metadata":{}},{"cell_type":"code","source":"# Handle missing values by dropping columns with excessive missing values\ntrain = train.dropna(axis=1, thresh=int(0.9 * len(train)))  # Drop columns with more than 10% missing values\n\n# Impute missing values with median\ntrain = train.fillna(train.median())\n\n# Define features and target\nfeatures = [col for col in train.columns if 'feature' in col]  # Select feature columns\nX = train[features]\ny = train['action']\n\n# Scale the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n?","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-04T09:18:35.573Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering\n\nIn finance, feature engineering is crucial. We might want to add aggregate statistics like rolling means or differences between features.","metadata":{}},{"cell_type":"code","source":"# Create additional features such as the mean and std deviation of the features\nX['mean'] = X.mean(axis=1)\nX['std'] = X.std(axis=1)\n\n# Feature engineering: percentage changes or rolling means\nX['pct_change'] = X.pct_change(axis=1).mean(axis=1)  # Example of percentage change across features\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-04T09:18:35.573Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build the Model\n\nHere we use LightGBM or XGBoost, which are both powerful models that can handle high-dimensional datasets well. We'll use cross-validation to assess performance and tune hyperparameters.","metadata":{}},{"cell_type":"code","source":"# Set up the LightGBM model\nlgb_train = lgb.Dataset(X_train, label=y_train)\nlgb_eval = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n\n# Parameters for the model\nparams = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'boosting_type': 'gbdt',\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n}\n\n# Train the model\nbst = lgb.train(params,\n                lgb_train,\n                valid_sets=[lgb_eval],\n                num_boost_round=1000,\n                early_stopping_rounds=100)\n\n# Make predictions\ny_pred = bst.predict(X_val, num_iteration=bst.best_iteration)\n\n# Evaluate the model using ROC AUC\nroc_auc = roc_auc_score(y_val, y_pred)\nprint(f'ROC AUC Score: {roc_auc}')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-04T09:18:35.573Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Eval\n\nWe can also evaluate the model using cross-validation to ensure stability.","metadata":{}},{"cell_type":"code","source":"# Cross-validation\ncv_results = lgb.cv(params, lgb_train, num_boost_round=1000, early_stopping_rounds=100, nfold=5, stratified=True, seed=42)\nprint(f\"Best AUC: {max(cv_results['auc-mean'])}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-04T09:18:35.574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Model & Pred","metadata":{}},{"cell_type":"code","source":"# Preprocess the test set\ntest_scaled = scaler.transform(test[features])  # Scale test features\n\n# Make final predictions\ntest_predictions = bst.predict(test_scaled, num_iteration=bst.best_iteration)\n\n# Prepare the output file in Kaggle format\noutput = pd.DataFrame({'id': test['id'], 'action': test_predictions})\noutput.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-04T09:18:35.574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-04T09:18:35.575Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This notebook provides a comprehensive approach to solving the Jane Street Market Data Forecasting challenge. By carefully exploring the data, applying preprocessing, feature engineering, and building robust models like LightGBM and XGBoost, we can develop a model that predicts market actions effectively. The submission file generated follows the Kaggle competition format, ready for evaluation.\n\nThis solution should be easy to understand and replicate, and you can further optimize and tune the model based on additional exploration and insights!","metadata":{}},{"cell_type":"code","source":"# enfin","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-04T09:18:35.575Z"}},"outputs":[],"execution_count":null}]}