{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84795,"databundleVersionId":10462807,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"To solve the Konwinski Prize competition on Kaggle, we need to approach the problem by developing a Python solution that automatically addresses GitHub issues using AI. This involves building a system capable of reading and understanding GitHub issues and using AI to suggest potential fixes, comments, or even create pull requests based on the issues. The challenge emphasizes the use of open-source code and open-weight models. The goal is to make it easier for human software engineers to focus on more strategic, creative tasks while automating issue resolution in the software development process.\n\nBelow is a comprehensive step-by-step Python solution template for this competition. The code outlines the major steps, including data preparation, model training, issue analysis, prediction generation, and submission creation.\n\n### Step-by-Step Python Script for GitHub Issue Automation\n\nStep 1: Setup and Install Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets scikit-learn numpy pandas matplotlib torch openai gitpython","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-04T10:19:37.991750Z","iopub.execute_input":"2025-01-04T10:19:37.992092Z"},"_kg_hide-input":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Installations","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\nfrom datasets import load_dataset\nfrom sklearn.model_selection import train_test_split\nimport openai\nimport git\nimport os\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and Preprocess Data","metadata":{}},{"cell_type":"code","source":"# Load GitHub issues dataset or GitHub issue data from an external file\ndef load_issues_data(filepath):\n    issues_df = pd.read_csv(filepath)\n    issues_df = issues_df.dropna(subset=['issue_title', 'issue_description'])\n    return issues_df\n\n# Example: Loading issues data from a CSV file\nissues_data = load_issues_data(\"github_issues_data.csv\")\nissues_data.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## The dataset might contain columns like:\n\n- issue_id: Unique identifier for the issue.\n- issue_title: Title of the GitHub issue.\n- issue_description: Description of the issue.\n- labels: Labels assigned to the issue (bug, enhancement, etc.).\n- issue_comments: A history of comments made on the issue.\n\n## Tokenization and Model Preparation\n\nWe'll use a pre-trained language model to classify or suggest comments on GitHub issues. In this case, we can leverage a transformer model such as BERT or GPT-3 for generating responses or code fixes for the issues.","metadata":{}},{"cell_type":"code","source":"# Load pre-trained tokenizer and model\nmodel_name = \"microsoft/deberta-v3-small\"  # You can choose a model that works best for GitHub issue categorization\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n\n# Alternatively, use a pre-trained GPT model for more advanced text generation (fixes, suggestions)\nopenai.api_key = \"your_openai_api_key\"  # To use GPT-3 or similar models\n\n# Function to generate suggestions for GitHub issues using GPT-3\ndef generate_suggestion_for_issue(issue_title, issue_description):\n    prompt = f\"Issue Title: {issue_title}\\nIssue Description: {issue_description}\\n\\nWhat is the solution or suggestion?\"\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",  # You can also use other GPT-3 models\n        prompt=prompt,\n        max_tokens=150\n    )\n    return response.choices[0].text.strip()\n\n# Example suggestion for one issue\nsample_issue_title = \"Fix bug in user authentication\"\nsample_issue_description = \"There is an issue where the login is not working when using Facebook login.\"\nsuggestion = generate_suggestion_for_issue(sample_issue_title, sample_issue_description)\nprint(\"Suggested Fix:\", suggestion)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train or Fine-Tune the Model\n\nIf you're not using a model like GPT-3 for suggestion generation but rather want to fine-tune a model for specific tasks (such as issue classification), you can proceed as follows. Weâ€™ll train a classification model based on the issue title and description to predict the category of the issue.","metadata":{}},{"cell_type":"code","source":"# Split the data into training and test sets\ntrain_data, test_data = train_test_split(issues_data, test_size=0.2)\n\n# Tokenize the text data for training\ndef tokenize_data(data, tokenizer):\n    return tokenizer(list(data['issue_title'] + \" \" + data['issue_description']), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n\ntrain_encodings = tokenize_data(train_data, tokenizer)\ntest_encodings = tokenize_data(test_data, tokenizer)\n\n# Create dataset class\nclass GitHubIssuesDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Train the model\ntrain_dataset = GitHubIssuesDataset(train_encodings, train_data['labels'].values)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n\n# Fine-tune the model using a training loop\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n\nfor epoch in range(3):  # Number of epochs\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        inputs = {key: value.to(model.device) for key, value in batch.items()}\n        labels = batch['labels'].to(model.device)\n        outputs = model(**inputs)\n        loss = torch.nn.CrossEntropyLoss()(outputs.logits, labels)\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch {epoch + 1}: Loss {loss.item()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation\n\nAfter training, we need to evaluate our model performance on the test set.","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the test data\ndef evaluate_model(model, test_data, tokenizer):\n    model.eval()\n    test_encodings = tokenize_data(test_data, tokenizer)\n    test_dataset = GitHubIssuesDataset(test_encodings, test_data['labels'].values)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)\n\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():\n        for batch in test_loader:\n            inputs = {key: value.to(model.device) for key, value in batch.items()}\n            labels = batch['labels'].to(model.device)\n            outputs = model(**inputs)\n            predictions = torch.argmax(outputs.logits, dim=-1)\n\n            correct_predictions += (predictions == labels).sum().item()\n            total_predictions += labels.size(0)\n\n    accuracy = correct_predictions / total_predictions\n    print(f\"Model Accuracy: {accuracy:.4f}\")\n\n# Evaluate the trained model\nevaluate_model(model, test_data, tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generate Predictions and Submit to Kaggle\n\nAfter the model is trained and evaluated, we can generate predictions for new GitHub issues in the test set and prepare the submission to Kaggle.","metadata":{}},{"cell_type":"code","source":"# Generate predictions for the test set\ndef generate_predictions_for_submission(test_data):\n    predictions = []\n    for _, row in test_data.iterrows():\n        suggestion = generate_suggestion_for_issue(row['issue_title'], row['issue_description'])\n        predictions.append(suggestion)\n    return predictions\n\n# Generate predictions for the test set\ntest_predictions = generate_predictions_for_submission(test_data)\n\n# Prepare the Kaggle submission file\nsubmission_df = pd.DataFrame({\n    'issue_id': test_data['issue_id'],\n    'predicted_suggestion': test_predictions\n})\n\n# Save submission file\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion\nThis Python solution template demonstrates how to solve the Konwinski Prize competition challenge. The script covers:\n\n- Data loading and preprocessing: Load GitHub issue data and preprocess it.\n- Modeling: Use a transformer model for issue classification or GPT-3 for generating suggestions/fixes for GitHub issues.\n- Model training: Fine-tune a transformer model to classify issues or suggest fixes.\n- Evaluation: Evaluate the model performance on the test set.\n- Prediction generation: Use the trained model to generate predictions and suggestions for GitHub issues.\n- Submission: Prepare the Kaggle submission file.\n\nThis solution leverages open-source models, uses transformers for advanced NLP tasks, and generates practical, actionable outputs for software engineers to review and act upon.","metadata":{}},{"cell_type":"code","source":"# enfin/","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}